{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "8c7b3825-1d60-479a-8a64-1b2887ff8dae",
        "_uuid": "a82e2ad6a19c9ce75530f0b3a3c4a21c8c82a006"
      },
      "cell_type": "markdown",
      "source": "This tutorial provides an overview of the DonorsChoose data set, as well as a quick-start guide to building your first model in TensorFlow and submitting your entry to Kaggle. \n\nFor a refresher on machine learning fundamentals, check out [Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course/). For more practice building models in TensorFlow, check out the [companion exercises](https://developers.google.com/machine-learning/crash-course/exercises#programming)."
    },
    {
      "metadata": {
        "_cell_guid": "fa3052cd-3b4c-4ba7-b9d2-d18959163aea",
        "_uuid": "2c2fb7b184624a65c9f7481225c5b1eeff3fe402"
      },
      "cell_type": "markdown",
      "source": "# About the DonorsChoose Data Set\n\nThe goal of the DonorsChoose competition is to build a model that can accurately predict whether a teacher's project proposal was accepted, based on the data they provided in their application. The `train.csv` data set provided by DonorsChoose contains the following features:\n\nFeature | Description | Data Type\n----------|---------------|------------\n**`project_id`** | A unique identifier for the proposed project. **Example:** `p036502`   | string\n**`project_title`**    | Title of the project. **Examples:**<br><ul><li><code>Art Will Make You Happy!</code></li><li><code>First Grade Fun</code></li></ul> | string\n**`project_grade_category`** | Grade level of students for which the project is targeted. One of the following enumerated values: <br/><ul><li><code>Grades PreK-2</code></li><li><code>Grades 3-5</code></li><li><code>Grades 6-8</code></li><li><code>Grades 9-12</code></li></ul>  | string\n **`project_subject_categories`** | One or more (comma-separated) subject categories for the project from the following enumerated list of values:  <br/><ul><li><code>Applied Learning</code></li><li><code>Care &amp; Hunger</code></li><li><code>Health &amp; Sports</code></li><li><code>History &amp; Civics</code></li><li><code>Literacy &amp; Language</code></li><li><code>Math &amp; Science</code></li><li><code>Music &amp; The Arts</code></li><li><code>Special Needs</code></li><li><code>Warmth</code></li></ul><br/> **Examples:** <br/><ul><li><code>Music &amp; The Arts</code></li><li><code>Literacy &amp; Language, Math &amp; Science</code></li>  | string\n  **`school_state`** | State where school is located ([Two-letter U.S. postal code](https://en.wikipedia.org/wiki/List_of_U.S._state_abbreviations#Postal_codes)). **Example:** `WY`| string\n**`project_subject_subcategories`** | One or more (comma-separated) subject subcategories for the project. **Examples:** <br/><ul><li><code>Literacy</code></li><li><code>Literature &amp; Writing, Social Sciences</code></li></ul> | string\n**`project_resource_summary`** | An explanation of the resources needed for the project. **Example:** <br/><ul><li><code>My students need hands on literacy materials to manage sensory needs!</code</li></ul> | string\n**`project_essay_1`**    | First paragraph of application essay.<sup>*</sup>  | string\n**`project_essay_2`**    | Second paragraph of application essay.<sup>*</sup> | string\n**`project_essay_3`**    | Third paragraph of application essay.<sup>*</sup> | string\n**`project_essay_4`**    | Fourth paragraph of application essay.<sup>*</sup> | string\n**`project_submitted_datetime`** | Datetime when project application was submitted. **Example:** `2016-04-28 12:43:56.245`   | int64\n**`teacher_id`** | A unique identifier for the teacher of the proposed project. **Example:** `bdf8baa8fedef6bfeec7ae4ff1c15c56`  | string\n**`teacher_prefix`** | Teacher's title. One of the following enumerated values: <br/><ul><li><code>nan</code></li><li><code>Dr.</code></li><li><code>Mr.</code></li><li><code>Mrs.</code></li><li><code>Ms.</code></li><li><code>Teacher.</code></li></ul>  | string\n**`teacher_number_of_previously_posted_projects`** | Number of project applications previously submitted by the same teacher. **Example:** `2` | int64\n\n<sup>\\*</sup> See **A Note on Essay Data** for some important details about changes to the application essay prompts in February 2010 that affect the values of `project_essay_1`, `project_essay_2`, `project_essay_3`, and `project_essay_4`.\n\nAdditionally, the `resources.csv` data set provides more data about the resources required for each project. Each line in this file represents a resource required by a project:\n\nFeature | Description | Data Type\n----------|---------------|------------\n**`id`** | A `project_id` value from the `train.csv` file.  **Example:** `p036502`   | string\n**`description`** | Desciption of the resource. **Example:** `Tenor Saxophone Reeds, Box of 25`   | string\n**`quantity`** | Quantity of the resource required. **Example:** `3`   | string\n**`price`** | Price of the resource required. **Example:** `9.95`   | string\n\n**Note:** Many projects require multiple resources. The `id` value corresponds to a `project_id` in train.csv, so you use it as a key to retrieve all resources needed for a project:\n\nThe data set contains the following label (the value you will attempt to predict):\n\nLabel | Description | Data Type\n----------|---------------|------------\n`project_is_approved` | A binary flag indicating whether DonorsChoose approved the project. A value of `0` indicates the project was not approved, and a value of `1` indicates the project was approved. | int64"
    },
    {
      "metadata": {
        "_cell_guid": "55d29c9a-9f20-40e3-9100-04e8f1796e07",
        "_uuid": "a4a00b075593184fc464e62f6f99758076b16041"
      },
      "cell_type": "markdown",
      "source": "### A Note on Essay Data\n\nPrior to February 18th, 2010, for their DonorsChoose application, teachers had the option of writing either a free-form essay (split into `project_essay_1`, `project_essay_2`, `project_essay_3`, and `project_essay_4`) or writing free-form answers to the following four prompts:\n\n1. Introduce your classroom (`project_essay_1`)\n2. Describe the situation (`project_essay_2`)\n3. Describe the solution (`project_essay_3`)\n4. Empower your donors (`project_essay_4`) \n\nEffective February 18th, 2010, the option to write a free-form essay was removed, and all teachers were required to respond to the following four prompts:\n\n1. Open with the challenge facing your students (`project_essay_1`)\n2. Tell us more about your students (`project_essay_2`)\n3. Inspire your potential donors with an overview of the resources you're requesting (`project_essay_3`)\n4. Close by sharing why your project is so important (`project_essay_4`) \n\nWhen using essay data from `project_essay_1`, `project_essay_2`, `project_essay_3`, and `project_essay_4`, make sure to take into account that the nature of the text content in these fields is different for examples with a `project_submitted_datetime` prior to February 18th, 2010."
    },
    {
      "metadata": {
        "_cell_guid": "b19a0e22-beb7-41fa-9f5b-a64bb7098731",
        "_uuid": "66c4d0182b4651c30127ff56914a01ecdcc808db"
      },
      "cell_type": "markdown",
      "source": "## Explore the DonorsChoose Data\n\nLet's explore our data using [pandas](https://pandas.pydata.org/), an open source Python data analysis library. (For more practice using pandas, see the  [Quick Introduction to pandas](https://colab.research.google.com/notebooks/mlcc/intro_to_pandas.ipynb) workbook. We'll also import [matplotlib](https://matplotlib.org/) to do some data visualizations.\n\nFirst, run the following cell to import pandas and matplotlib:"
    },
    {
      "metadata": {
        "_cell_guid": "6496b8ea-0669-4060-8e74-9781a3b83990",
        "_uuid": "6be9c6287dc01cd729308266b16a5ef61c999923",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "import pandas as pd\nfrom matplotlib import pyplot as plt",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "f5ada641-2a72-473b-85e6-8bdfc53233ca",
        "_uuid": "2e7c9da2bb8e57e7d3d6300ef4a6c7362e1a10d4"
      },
      "cell_type": "markdown",
      "source": "Next, read the DonorsChoose training data into a `DataFrame`:"
    },
    {
      "metadata": {
        "_cell_guid": "98fcf917-cda3-4596-b538-3df27f9f5f0e",
        "_uuid": "0889eefe3df46fff71f8442d6607ee52e8f491f9",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Filepath to main training dataset.\ntrain_file_path = '../input/train.csv'\n\n# Read data and store in DataFrame.\ntrain_data = pd.read_csv(train_file_path, sep=',')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "0aec80ec-9bdb-476f-b002-311bc9e2adc6",
        "_uuid": "06a16246878db2b231650de036e89fca65c5ee09"
      },
      "cell_type": "markdown",
      "source": "List all the fields in the data set:"
    },
    {
      "metadata": {
        "_cell_guid": "98dbc86c-316f-4b0e-b78e-617b35f2da98",
        "_uuid": "790077ba2f255af655d17b33b767d30c5a66a224",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "train_data.columns",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "56a1d80d-5d37-4a80-a23f-bca5ebe7e4db",
        "_uuid": "3ec8da52fd1edce18862905e624747acad2a6aed"
      },
      "cell_type": "markdown",
      "source": "Retrieve the first three examples:"
    },
    {
      "metadata": {
        "_cell_guid": "465ba7bc-f80c-440a-8f47-16c404cd2187",
        "_uuid": "fb44ce4af7d24d6cee0ef95f54e6a05eda7e3e57",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "train_data.head(3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "f297bfa3-fd11-4cd8-9600-fc1cb26e82a9",
        "_uuid": "e68fbacc7118bf981c2510b4f3f6e36894fe2c42"
      },
      "cell_type": "markdown",
      "source": "Let's take a closer look at our one numeric feature, `teacher_number_of_previously_posted_projects`. Print some key stats using the  `describe()` method:"
    },
    {
      "metadata": {
        "_cell_guid": "e390e904-3ce4-436c-8d6a-2d4fc2511f8c",
        "_uuid": "f77ce659218fbdc0faf25d5cd485ddb9a5c3e919",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Describe data set and retrieve data for teacher_number_of_previously_posted_projects\ntrain_data.describe()[\"teacher_number_of_previously_posted_projects\"]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "358086a1-a3e1-40de-96da-b2ad68827b90",
        "_uuid": "e94c8fd19bf6637e1fcd3d7c6d7285af15f6c29c"
      },
      "cell_type": "markdown",
      "source": "We can see that the minumum number of previously posted projects for a teacher is 0, the maximum number is 451, and the mean (average) number is 11.23. Let's visualize the distribution using a histogram, to get a better sense of the spread."
    },
    {
      "metadata": {
        "_cell_guid": "9c9550e1-c071-4087-9c26-f0a680eba26f",
        "_uuid": "6c05409387f112fd1e3ea016583a408f2a8e097a",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Plot histogram with 45 bins; each bin representing a range of 10\nplt.hist(train_data[\"teacher_number_of_previously_posted_projects\"], bins=45)\nplt.xticks(range(0, 500, 50))\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "131cfeaf-316f-4497-98b3-0e1539dc74c5",
        "_uuid": "dc317c7818e43c18058b9610c6a13064a8cdacef"
      },
      "cell_type": "markdown",
      "source": "We can see that the vast majority of examples have a `teacher_number_previously_posted_projects` value between 0 and 10, with a sharp dropoff thereafter. However, if we rebucket our data into two bins (&lt; 10 and &ge; 10), we can see that there's a substantial long tail of examples with previously-posted-project values greater than 10:"
    },
    {
      "metadata": {
        "_cell_guid": "1759ab1f-6cfc-4d59-ab66-0d21040bf955",
        "_uuid": "2b00fb5cc71d2f09c7c65727b092cc1496e47dad",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Plot histogram with 45 bins; each bin representing a range of 10\nplt.hist(train_data[\"teacher_number_of_previously_posted_projects\"], bins=[0, 10, 450])\nplt.xticks(range(0, 500, 50))\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "d40d917a-405e-446a-88c5-ff843c071c67",
        "_uuid": "78839e4e8e5b045b74d036f77fc457a13c9b3703"
      },
      "cell_type": "markdown",
      "source": "## Build an Initial Linear Classification Model\n\nPerhaps `teacher_number_of_previously_posted_projects` might provide a good signal as to whether a DonorsChoose application will be accepted? We can hypothesize that teachers who have submitted a large number of previous projects may be more familiar with the ins and outs of the application process and less likely to make errors that would lead to a rejection.\n\nLet's test that theory by building a simple linear classification model that predicts the `project_is_approved` value solely from the `teacher_number_of_previously_posted_projects` feature. We'll build our model in TensorFlow using a `LinearClassifier` from the high-level [Estimators API](https://www.tensorflow.org/programmers_guide/estimators). \n\n**NOTE:** For more practice in building TensorFlow models with `Estimator`s, see the Machine Learning Crash Course [companion exercises](https://developers.google.com/machine-learning/crash-course/exercises#programming). \n\nFirst, import the modules we'll use, which include TensorFlow, the TensorFlow [Datasets API](https://www.tensorflow.org/get_started/datasets_quickstart), [numpy](http://www.numpy.org/), and [scikit-learn](http://scikit-learn.org/) (for some convenience functions for metrics):"
    },
    {
      "metadata": {
        "_cell_guid": "e3c45ba3-a75e-4a45-b155-37802e9c0fbc",
        "_uuid": "1e27554fb69de6781ce4c7d94141fd23f4273aca",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "import tensorflow as tf\nfrom tensorflow.python.data import Dataset\nimport numpy as np\nimport sklearn.metrics as metrics",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "6a360330-0e71-4758-95a9-2a647bcbfdda",
        "_uuid": "54cc1d8081817f9d9c0f73d0b18a0765042984fe"
      },
      "cell_type": "markdown",
      "source": "If you didn't import the DonorsChoose training data above, do so now:"
    },
    {
      "metadata": {
        "_cell_guid": "db507783-fad3-484c-86a9-2b971a2da955",
        "_uuid": "7f2ddeae8035bf8c0bd8c9389f6e047a02572e38",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "import pandas as pd\n\n# Filepath to main training dataset.\ntrain_file_path = '../input/train.csv'\n\n# Read data and store in DataFrame.\ntrain_data = pd.read_csv(train_file_path, sep=',')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "015ce368-dcc7-4429-b52c-b3c56335cee5",
        "_uuid": "1944287a177b1cf23d21e3d098cbc2282ae7dab3"
      },
      "cell_type": "markdown",
      "source": "Next, define the feature (`teacher_number_of_previously_posted_projects`) and label (`project_is_approved`):"
    },
    {
      "metadata": {
        "_cell_guid": "5f8b0af9-1269-4246-b9ec-14505d0778cd",
        "_uuid": "fcf4bf7f41d76540be09af3f402946b1e2a2b568",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Define predictor feature(s); start with a simple example with one feature.\nmy_feature_name = 'teacher_number_of_previously_posted_projects'\nmy_feature = train_data[[my_feature_name]]\n\n# Specify the label to predict.\nmy_target_name = 'project_is_approved'",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "c1dad132-7ed5-45ec-8182-9c3e7dcdf956",
        "_uuid": "2c2e671984d51a1c726149645c95d66fa4659dbf"
      },
      "cell_type": "markdown",
      "source": "Then split the data into training and validation sets:"
    },
    {
      "metadata": {
        "_cell_guid": "c26689d6-1d0d-4afb-9414-6c5b716a9c38",
        "_uuid": "cd56bb7fbf648a21a90c4a9175d567d0811c5d78",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Prepare training and validation sets.\nN_TRAINING = 160000\nN_VALIDATION = 100000\n\n# Choose examples and targets for training.\ntraining_examples = train_data.head(N_TRAINING)[[my_feature_name]].copy()\ntraining_targets = train_data.head(N_TRAINING)[[my_target_name]].copy()\n\n# Choose examples and targets for validation.\nvalidation_examples = train_data.tail(N_VALIDATION)[[my_feature_name]].copy()\nvalidation_targets = train_data.tail(N_VALIDATION)[[my_target_name]].copy()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "e0fe0bf5-bbc7-4c09-b073-be937d8f3ebd",
        "_uuid": "3f89a2ed6e3517854791ab266e5681d7aa7c07ba"
      },
      "cell_type": "markdown",
      "source": "Then set up the input function to feed data into the model using the [Datasets API](https://www.tensorflow.org/get_started/datasets_quickstart):"
    },
    {
      "metadata": {
        "_cell_guid": "bcb3e9f3-5403-400a-8f09-39783ec88f79",
        "_uuid": "66434d85cfecbdcf67c191acc2f39bbd42282df6",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n    \"\"\"Trains a linear regression model of one feature.\n  \n    Args:\n      features: pandas DataFrame of features\n      targets: pandas DataFrame of targets\n      batch_size: Size of batches to be passed to the model\n      shuffle: True or False. Whether to shuffle the data.\n      num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely\n    Returns:\n      Tuple of (features, labels) for next data batch\n    \"\"\"\n    \n    # Convert pandas data into a dict of np arrays.\n    features = {key:np.array(value) for key,value in dict(features).items()}                                           \n \n    # Construct a dataset, and configure batching/repeating\n    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n    ds = ds.batch(batch_size).repeat(num_epochs)\n    \n    # Shuffle the data, if specified\n    if shuffle:\n      # Shuffle with a buffer size of 10000\n      ds = ds.shuffle(10000)\n    \n    # Return the next batch of data\n    features, labels = ds.make_one_shot_iterator().get_next()\n    return features, labels",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "50c2c0f9-9d2b-4d9f-90f0-7008ffff2471",
        "_uuid": "87794482c969cf79a656a2738b3a90012a96ae84"
      },
      "cell_type": "markdown",
      "source": "Next, construct the `LinearClassifier`:"
    },
    {
      "metadata": {
        "_cell_guid": "a14e210f-ebf6-49de-ac4d-5320cb7abc9d",
        "_uuid": "b80465e3ca528f7f7d7f0337e8ac4fd9033b86c5",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Learning rate for training.\nlearning_rate = 0.00001\n\n# Function for constructing feature columns from input features\ndef construct_feature_columns(input_features):\n  \"\"\"Construct the TensorFlow Feature Columns.\n  Args:\n    input_features: The names of the numerical input features to use.\n  Returns:\n    A set of feature columns\n  \"\"\"\n  return set([tf.feature_column.numeric_column(my_feature)\n              for my_feature in input_features])\n\n# Create a linear classifier object.\nmy_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n# Set a clipping ratio of 5.0\nmy_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)  \nlinear_classifier = tf.estimator.LinearClassifier(\n    feature_columns=construct_feature_columns(training_examples),\n    optimizer=my_optimizer\n)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "5d4ac88b-c9c7-4bf4-b8a8-7a66b6a8edf3",
        "_uuid": "539ae2d007b484f026fd9f636432b7a6291c0aaf"
      },
      "cell_type": "markdown",
      "source": "Create input functions for training the model, predicting on the prediction data, and predicting on the validation data:"
    },
    {
      "metadata": {
        "_cell_guid": "131694ac-5538-4d3f-913c-07217af970c2",
        "_uuid": "296e8531a15de6b433654f9782c034d154ff2d58",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "batch_size = 10\n\n# Create input function for training\ntraining_input_fn = lambda: my_input_fn(training_examples, \n                                        training_targets[my_target_name],\n                                        batch_size=batch_size)\n\n# Create input function for predicting on training data\npredict_training_input_fn = lambda: my_input_fn(training_examples,\n                                                training_targets[my_target_name],\n                                                num_epochs=1, \n                                                shuffle=False)\n\n# Create input function for predicting on validation data\npredict_validation_input_fn = lambda: my_input_fn(validation_examples,\n                                                  validation_targets[my_target_name],\n                                                  num_epochs=1, \n                                                  shuffle=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "ddd78749-3264-44a0-9692-20c4db287284",
        "_uuid": "93bb6e339a7c98f9b542d07efdf75820c56325d8"
      },
      "cell_type": "markdown",
      "source": "Finally, train the model. This may take a few minutes. When training is complete, the training and validation log losses will be output:"
    },
    {
      "metadata": {
        "_cell_guid": "dc2fe166-20ca-452d-8def-570b1d09846b",
        "_uuid": "d504895bbc171585c764173e9d3d3157ad844492",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Train for 200 steps\nlinear_classifier.train(\n  input_fn=training_input_fn,\n  steps=200\n)\n\n# Compute predictions.    \ntraining_probabilities = linear_classifier.predict(\n    input_fn=predict_training_input_fn)\ntraining_probabilities = np.array(\n      [item['probabilities'] for item in training_probabilities])\n    \nvalidation_probabilities = linear_classifier.predict(\n    input_fn=predict_validation_input_fn)\nvalidation_probabilities = np.array(\n    [item['probabilities'] for item in validation_probabilities])\n    \ntraining_log_loss = metrics.log_loss(\n    training_targets, training_probabilities)\nvalidation_log_loss = metrics.log_loss(\n    validation_targets, validation_probabilities)\n  \n# Print the training and validation log loss.\nprint(\"Training Loss: %0.2f\" % training_log_loss)\nprint(\"Validation Loss: %0.2f\" % validation_log_loss)\n\nauc = metrics.auc",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "18052754-7207-4a94-a648-5685bfdcc485",
        "_uuid": "7b9bf9c7d30be5969464a01cefa21b5cae3e8034"
      },
      "cell_type": "markdown",
      "source": "Next, let's calculate the [AUC (area under the curve)](https://developers.google.com/machine-learning/glossary#AUC), which is the metric this competition uses to assess the accuracy of prediction. This may take a few minutes. When calculation is complete, the training and validation AUC values will be output:"
    },
    {
      "metadata": {
        "_cell_guid": "e2efa7b9-2108-4a62-bf35-de6e555a8314",
        "_uuid": "2cd1d81085ac1ddd60f54c2ffd032873ef2d1127",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "training_metrics = linear_classifier.evaluate(input_fn=predict_training_input_fn)\nvalidation_metrics = linear_classifier.evaluate(input_fn=predict_validation_input_fn)\n\nprint(\"AUC on the training set: %0.2f\" % training_metrics['auc'])\nprint(\"AUC on the validation set: %0.2f\" % validation_metrics['auc'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "47634480-fc44-4054-bc3b-aa4d9295e35f",
        "_uuid": "615410917a05455fb83e3f375008b0d512d7ec81",
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "We've achieved AUC values of 0.56, which is slightly better than random. This is a good start, but can you improve the model to achieve better results?"
    },
    {
      "metadata": {
        "_cell_guid": "9ac45f65-1fb3-4e99-803e-e48109b17a89",
        "_uuid": "d98cae3eb1cf7b4681fcc76b41460134f4ccca0b"
      },
      "cell_type": "markdown",
      "source": "## What to Try Next\n\nA couple ideas for model refinements you can try to see if you can improve model accuracy:\n\n* Try adjusting the `learning_rate` and `steps` hyperparameters on the existing model.\n* Try adding some text features to the model, such as the content of the project essays (`project_essay_1`, `project_essay_2`, `project_essay_3`, `project_essay_4`). You may want to try building a vocabulary from these strings; see the Machine Learning Crash Course [Intro to Sparse Data and Embeddings exercise](https://colab.research.google.com/notebooks/mlcc/intro_to_sparse_data_and_embeddings.ipynb) for some practice on working with text data and vocabularies.  "
    },
    {
      "metadata": {
        "_cell_guid": "6ddce170-e244-4500-9698-df592b33269c",
        "_uuid": "c7b2493328aed953d41e5a3bdd82290bfa34b938"
      },
      "cell_type": "markdown",
      "source": "## Submitting a Kaggle Entry\n\nOnce you're satisfied with your model performance, you can make predictions on the test set as follows (this may take a few minutes to run):"
    },
    {
      "metadata": {
        "_cell_guid": "6841ed06-9490-4cc2-8b8d-8737ff445d74",
        "_uuid": "1b10151e274bbae0d29d436f478e718d3c452c24",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Filepath to main test dataset.\ntest_file_path = '../input/test.csv'\n\n# Read data and store in DataFrame.\ntest_data = pd.read_csv(test_file_path, sep=',')\n\nmy_feature_name = 'teacher_number_of_previously_posted_projects'\n\n# Get test features\ntest_examples = test_data[[my_feature_name]].copy()\n\n# No labels in data set, so generate some placeholder values\nplaceholder_label_vals = [0 for i in range(0, 78035)]\ntest_labels = pd.DataFrame({\"project_is_approved\": placeholder_label_vals})\n\npredict_test_input_fn = lambda: my_input_fn(test_examples,\n                                            test_labels, # unused for prediction\n                                            num_epochs=1, \n                                            shuffle=False)\n\n# Make predictions\npredictions_generator = linear_classifier.predict(input_fn=predict_test_input_fn)\npredictions_list = list(predictions_generator)\n\n# Extract probabilities\nprobabilities = [p[\"probabilities\"][1] for p in predictions_list]\nprint(\"Done extracting probabilities\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "00359193-3d73-4581-83d3-0719d96327fc",
        "_uuid": "f80792ff0418734b93c365b1c464367e3f164d89"
      },
      "cell_type": "markdown",
      "source": "We want to format our submission as a CSV with two fields for each example: `id` and our prediction for `project_is_approved`, e.g.:"
    },
    {
      "metadata": {
        "_cell_guid": "48f2793c-7491-46a5-b1ed-ed33fb5e4b93",
        "_uuid": "05d72bb9c705bf49b608ce709880c9ac4062f60b"
      },
      "cell_type": "markdown",
      "source": "```\nid,project_is_approved\np233245,0.54\np096795,0.14\np236235,0.94\n```"
    },
    {
      "metadata": {
        "_cell_guid": "3d26533e-8da6-4a8b-a42a-ed3f8f8bb863",
        "_uuid": "72a0a86fac985490c1f60856c69f132005724a8d"
      },
      "cell_type": "markdown",
      "source": "Run the following code to create a `DataFrame` in the required format:"
    },
    {
      "metadata": {
        "_cell_guid": "f581f01c-310c-477d-9fcc-9e27d49dc40b",
        "_uuid": "1f6c30bf8029a37e3aa70e0d12d9f819d3c43b59",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "my_submission = pd.DataFrame({'id': test_data[\"id\"], 'project_is_approved': probabilities})\nprint(my_submission.values)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "4676bc39-1d6b-4bbe-be44-ac4365a41aa4",
        "_uuid": "b6ef81d70456f42ec3f73ee73a8c4dc06d44e980"
      },
      "cell_type": "markdown",
      "source": "Then write your output to CSV:"
    },
    {
      "metadata": {
        "_cell_guid": "a2780929-98b9-4548-bdd6-c69223fe2cb8",
        "_uuid": "20f77cdd51262a69babd7cf13c9c639250b3c3eb",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "my_submission.to_csv('my_submission.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "cc951577-4e91-48b8-bbfd-b5afbcfae7de",
        "_uuid": "a182f503abc4b5923ec66f87049cd1f81340bbb1"
      },
      "cell_type": "markdown",
      "source": "Next, click the **Commit & Run** button to execute the entire Kaggle kernel. This will take ~10 minutes to run. \n\nWhen it's finished, you'll see the navigation bar at the top of your screen has an **Output** tab. Click on the **Output** tab, and click on the **Submit to Competition** button to submit to Kaggle."
    }
  ],
  "metadata": {
    "language_info": {
      "file_extension": ".py",
      "name": "python",
      "version": "3.6.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "nbconvert_exporter": "python",
      "mimetype": "text/x-python"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}